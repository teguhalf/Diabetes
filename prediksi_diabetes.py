# -*- coding: utf-8 -*-
"""Prediksi_Diabetes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/150aSlptjB_E1tYDyE2tfLQpXXksLj7kz

# **1. IMPORT LIBRARY**
"""

import pandas as pd # Manipulasi Data
import numpy as np # Komputasi Matematika
from sklearn.model_selection import train_test_split # Membagi dataset (train, val, test)
from sklearn.preprocessing import QuantileTransformer # Standardisasi
from sklearn.metrics import classification_report, confusion_matrix # Metrik Akurasi
import matplotlib.pyplot as plt # Visualisasi Data
import seaborn as sns # Visualisasi Data
import tensorflow as tf # Library Neural Network
from tensorflow.keras.models import Sequential # Input Layer
from tensorflow.keras.layers import Dense, Dropout # Fully Connected Layer dan Dropout Layer
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint # Callbacks

"""# **2. LOAD DATASET**

## Memasukkan dataset diabetes.csv
"""

df = pd.read_csv("diabetes.csv") # Membuat dataframe dengan nama df
df.head() # Menampilkan 5 baris teratas dataframe df

"""**TENTANG DATASET:** <br>
Dataset dalam penelitian ini berasal dari National Institute of Diabetes and Digestive and Kidney Diseases. Tujuan dari dikumpulkannya data ini adalah untuk memprediksi secara diagnostik apakah seorang pasien menderita diabetes, berdasarkan pengukuran diagnostik tertentu yang disertakan dalam kumpulan data. Dataset bersifat publik dengan format CSV (Comma Separated Value) yang dapat diakses melalui link berikut: https://www.kaggle.com/datasets/akshaydattatraykhare/diabetes-dataset <br> <br>
**INFORMASI KOLOM DI DATASET:**
- Pregnancies : Untuk menyatakan jumlah kehamilan
- Glucose : Untuk menyatakan kadar glukosa dalam darah
- BloodPressure : Untuk menyatakan pengukuran tekanan darah
- SkinThickness : Untuk menyatakan ketebalan kulit
- Insulin : Untuk menyatakan kadar insulin dalam darah
- BMI : Untuk menyatakan indeks massa tubuh
- DiabetesPedigreeFunction : Untuk menyatakan persentase diabetes
- Age : Untuk menyatakan usia
- Outcome : Untuk menyatakan hasil akhir 1 adalah ya dan 0 adalah tidak

# **3. EXPLORATORY DATA ANALYSIS**

## Melihat Informasi Dataset

Untuk mengetahui tipe data, jumlah row, jumlah kolom, dan memory yang dipakai
"""

# Mengidentifikasi informasi dataset
print('INFORMASI DATASET:')
print(df.info())

"""**Insight:**
- Terdapat 9 kolom di dalam dataset.
- Masing-masing kolom memiliki 768 baris.
- 7 kolom tipe data integer (Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, Age, Outcome).
- 2 kolom tipe data float (BMI, DiabetesPedigreeFunction)

## Melihat Deskripsi Statistik Dataset

Hal ini sangat bermanfaat untuk melihat statistik singkat data sebelum melakukan cleaning
"""

# Mengindentifikasi nilai statistik tiap kolom melalui deskripsi statistik
print('DESKRIPSI STATISTIK DATASET:')
print(df.describe())

"""**Insight:**
- Kolom Glucose, BloodPressure, SkinThickness, Insulin, dan BMI memiliki nilai minimum yang tidak rasional yaitu 0. Perlu dilakukan cleaning

## Cek Data yang Null

Memastikan data tidak ada yang null, karena data null akan mempengaruhi kualitas data yang dihasilkan.
<br>
GARBAGE IN, GARBAGE OUT
"""

# Mengindentifikasi data yang null
print('JUMLAH DATA NULL:')
print(df.isnull().sum())

"""## Cek Data Duplikat

Memastikan data tidak ada yang duplikat (kembar), karena data duplikat akan mempengaruhi kualitas data yang dihasilkan.
<br>
GARBAGE IN, GARBAGE OUT.
"""

# Mengindentifikasi data duplikat
print('JUMLAH DATA DUPLIKAT:')
print(df.duplicated().sum())

"""**Insight:**
- Tidak ada data null
- Tidak ada data duplikat

## Visualisasi Data

Melihat distribusi data dengan grafik histogram untuk melihat skewness-nya (kemiringan)
"""

# Visualisasi Distribusi Tiap Kolom
df.hist(bins=50, figsize=(10, 8))
plt.tight_layout()
plt.show()

"""**Insight:**
- Beberapa kolom yang Left Skewed: Pregnancies, SkinThickness, Insulin, DiabetesPedigreeFunction, Age.
- Neutral Skewed: Glucose, BloodPressure, BMI, Outcome

Mengetahui distribusi data berdasarkan rentang usia dengan diagram pie.<br>
1. Kelompok Remaja: Usia > 18 Tahun
2. Kelompok Dewasa: Usia 17 < x < 40 Tahun
3. Kelompok Tua: Usia > 39 Tahun
"""

# Membuat fungsi untuk membagi tiga rentang usia (Remaja, Dewasa, Tua)
def categorize_age(age):
  if 0 < age < 18:
    return 'Remaja'
  elif 18 <= age < 40:
    return 'Dewasa'
  elif age >= 40:
    return 'Tua'

# Membuat kolom Age_Group
df['Age_Group'] = df['Age'].apply(categorize_age)

# Visualisasi Pie Chart Blood Pressure Category
age_group_counts = df['Age_Group'].value_counts()
plt.figure(figsize=(4, 4))
plt.pie(age_group_counts, labels=age_group_counts.index, autopct='%1.1f%%', startangle=90, colors=['skyblue', 'lightgreen', 'salmon'])
plt.title('Distribusi Rentang Usia')
plt.show()

print('\nJumlah Data per Kelompok Usia:')
print(df['Age_Group'].value_counts())

"""**Insight:**
- Tidak ada kelompok Remaja
- Kelompok Dewasa sebesar 73% (561 orang).
- Kelompok Tua sebesar 27% (207)

Mengetahui distribusi data berdasarkan tekanan darah (BloodPressure) dengan diagram pie.<br>
1. Kelompok Tekanan Darah Rendah: > 80 mmHg
2. Kelompok Tekanan Darah Normal: 79 < x < 120 mmHg
3. Kelompok Tekanan Darah Tinggi: > 119 mmHg
"""

# Membuat fungsi untuk membagi tiga tipe Blood Pressure (Rendah, Normal, Tinggi)
def categorize_blood_pressure(bp):
  if bp < 80:
    return 'Rendah'
  elif 80 <= bp < 120:
    return 'Normal'
  elif bp >= 120:
    return 'Tinggi'

# Membuat kolom BloodPressure_Category
df['BloodPressure_Category'] = df['BloodPressure'].apply(categorize_blood_pressure)

# Visualisasi Pie Chart Blood Pressure Category
blood_pressure_counts = df['BloodPressure_Category'].value_counts()
plt.figure(figsize=(4, 4))
plt.pie(blood_pressure_counts, labels=blood_pressure_counts.index, autopct='%1.1f%%', startangle=90, colors=['skyblue', 'lightgreen', 'salmon'])
plt.title('Distribusi Kategori Tekanan Darah')
plt.show()

print('\nJumlah Data per Kategori Tekanan Darah:')
print(df['BloodPressure_Category'].value_counts())

"""Insight:
- Kelompok Tekanan Darah Rendah sebesar 73.3% (563 orang).
- Kelompok Tekanan Darah Normal sebesar 26.6% (563 orang).
- Kelompok Tekanan Darah Tinggi sebesar 0.1% (1 orang).

# **4. CLEANING DATA**

## Pembersihan Data Untuk Memastikan Supaya Data yang Digunakan Berkualitas

Mengubah nilai 0 pada beberapa kolom dengan nilai mean untuk menjaga rasionalitas data.
"""

# Ubah nilai 0 pada bbrp kolom dengan nilai rata-rata masing-masing kolom
columns_to_replace = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
for col in columns_to_replace:
    df[col] = df[col].replace(0, np.nan)
    df[col].fillna(df[col].mean(), inplace=True)

"""Menghapus kolom yang tidak digunakan untuk prediksi"""

df.drop('Age_Group', axis=1, inplace=True)
df.drop('BloodPressure_Category', axis=1, inplace=True)

"""## Penanganan Outlier Untuk Mencegah Gangguan Terhadap Hasil Prediksi

Identifikasi jumlah outlier dengan membuat fungsi interquartil
"""

# Membuat variabel cols berisikan semua kolom, kecuali Outcome
cols = df.columns.tolist()
cols.remove('Outcome')

# Identifikasi Outlier
def identify_outlier_iqr(data):
    outliers = []
    q1 = data.quantile(0.25)
    q3 = data.quantile(0.75)
    iqr = q3 - q1
    lower_bound = q1 - 1.5 * iqr # batas bawah
    upper_bound = q3 + 1.5 * iqr # batas atas
    for i in data:
        if i < lower_bound or i > upper_bound:
            outliers.append(i)
    return outliers

print('Sebelum Impute Outliers')
data_outlier = {} # Dictionary utk menyimpan nilai yg dianggap outlier
for col in cols:
    data_outlier[col] = identify_outlier_iqr(df[col])
    print('Outlier (' + col + '):', len(data_outlier[col]), 'outliers')

"""Penanganan outlier dengan mengubah nilai outlier yang melebihi batas atas dengan nilai upper_bound. Kemudian, mengubah nilai outlier yang kurang dari batas bawah dengan nilai lower_bound"""

# Fungsi untuk menangani outlier
def impute_outlier_iqr(df):
    Q1 = df.quantile(0.25) # Quartil 1
    Q3 = df.quantile(0.75) # Quartil 2
    IQR = Q3-Q1 # Interquartil
    lower_bound = Q1 - 1.5*IQR # Batas Bawah (BB)
    upper_bound = Q3 + 1.5*IQR # Batas Atas (BA)
    # Mengganti nilai outlier yg melebihi BA, dengan nilai BA
    df = np.where(df > upper_bound, upper_bound, df)
    # Mengganti nilai outlier yg kurang dari BB, dengan nilai BB
    df = np.where(df < lower_bound, lower_bound, df)
    return df

# Menerapkan fungsi ke semua kolom
for col in cols:
    df[col] = impute_outlier_iqr(df[col])

print('Setelah Drop Outliers')
data_outlier = {}
for col in cols:
    data_outlier[col] = identify_outlier_iqr(df[col])
    print('Outlier (' + col + '):', len(data_outlier[col]), 'outliers')

"""Insight:
- Diidentifikasi terdapat outlier di sebagian besar kolom.
- Setelah penanganan outlier, sudah tidak ada lagi kolom yang memiliki outlier

## Train Test Split dan Standardisasi

- Menentukan variabel X dan Y.
- Kolom pada variabel X:<br>
  1. Pregnancies
  2. Glucose
  3. BloodPressure
  4. SkinThickness
  5. Insulin
  6. BMI
  7. DiabetesPedigreeFunction
  8. Age
- Kolom pada variabel Y:<br>
  1. Outcome
- Melakukan standardisasi dengan QuantileTransformer. Tujuannya yaitu supaya distribusi data menjadi normal.
- Membagi data menjadi data train 49%, val 21%, dan test 30%.
"""

# Menentukan variabel X dan Y
X = df.drop('Outcome', axis=1) # Kolom selain 'Outcome'
y = df['Outcome'] # Hanya kolom 'Outcome'

# Quantile Transformer
scaler = QuantileTransformer()
X_scaled = scaler.fit_transform(X)

# Membagi dataset ke data train, data val, dan data test
X_temp, X_test, y_temp, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.3, random_state=42)

"""Menginstall library keras-tuner"""

!pip install keras-tuner

"""## Hyperparameter Tuning dengan Library keras_tuner

- Membangun fungsi untuk melakukan percobaan pencarian jumlah pada tiap layer, learning rate, dan optimizer
- Setup tuning untuk melakukan percobaan sebanyak 10 kali dengan masing-masing percobaan memiliki 50 iterasi (epochs).
- Evaluasi menggunakan accuracy dan loss binary_crossentropy karena hanya akan menghasilkan binary, 0 (Tidak Diabetes) dan 1 (Diabetes).
- Hasil dari tuning akan disimpan di folder tuning_diabetes dengan nama file diabetes_model.
"""

import keras_tuner as kt
from tensorflow.keras.optimizers import Adam

# Membangun fungsi untuk percobaan mencari jumlah layer terbaik
def build_model(hp):
    model = Sequential()
    # Input Layer
    model.add(Dense(
        units=hp.Int('units_input', min_value=16, max_value=64, step=16),
        activation='relu',
        input_shape=(X_train.shape[1],)))
    # Layer Dropout 1
    model.add(Dropout(hp.Float('dropout_1', 0.1, 0.3, step=0.1)))
    # Hidden Layer
    model.add(Dense(
        units=hp.Int('units_hidden', min_value=8, max_value=16, step=8),
        activation='relu'))
    # Layer Dropout 2
    model.add(Dropout(hp.Float('dropout_2', 0.1, 0.3, step=0.1)))
    # Output Layer
    model.add(Dense(1, activation='sigmoid'))

    # Menggunakan optimizer Adam
    optimizer_choice = hp.Choice('optimizer', values=['adam'])
    if optimizer_choice == 'adam':
        opt = Adam(learning_rate=hp.Choice('learning_rate', [1e-3, 1e-4]))

    model.compile(
        optimizer=opt,
        loss='binary_crossentropy',
        metrics=['accuracy']) # Metrik Akurasi

    return model

# Setup tuning
tuner = kt.RandomSearch(
    build_model, # Masukkan fungsi mencari jumlah layer terbaik
    objective='val_accuracy', # Akurasi pada data validation
    max_trials=10, # Jumlah Percobaan Tuning
    executions_per_trial=1, # Eksekusi Tiap Percobaan
    directory='tuning_diabetes', # Direktori File Hasil Tuning
    project_name='diabetes_model' # Nama File Tuning
)

# Menjalankan pencarian parameter
tuner.search(X_train, y_train, epochs=50, validation_data=(X_val, y_val), verbose=1)

# Mendapatkan model terbaik
best_model = tuner.get_best_models(num_models=1)[0]
best_hps = tuner.get_best_hyperparameters(1)[0]

print("\nBest Hyperparameters:")
for param in best_hps.values:
    print(f"{param}: {best_hps.values[param]}")

"""**Insight:**
- Hyperparameter tuning berhasil dijalankan dengan modul keras_tuner.
- Hasil dari tuning yaitu:
  - Akurasi best val_accuracy yaitu 0.80
  - Waktu yang dibutuhkan untuk 10 percobaan yaitu 2 menit 5 detik.
  - Layer input terbaik yaitu 32.
  - Layer dropout_1 terbaik yaitu 0.2
  - Layer dropout_2 terbaik yaitu 0.2
  - Layer Hidden terbaik yaitu 16.
  - Optimizer yang digunakan Adam dengan learning rate 0.001

## Membangun Model Multi Layer Perceptron
"""

# Buat model menggunakan dari hyperparameter tuning
from tensorflow.keras.optimizers import Adam

model = Sequential([
    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),
    Dropout(0.2),
    Dense(16, activation='relu'),
    Dropout(0.2),
    Dense(1, activation='sigmoid')
])

# Kompilasi model
model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# Ringkasan arsitektur
model.summary()

"""**Insight:**
- Menerapkan input layer, hidden layer, dropout layer, dan output layer.
- Input layer terdapat 32 neuron
- Dropout layer 1 dan 2 memiliki dropout rate 0.2
- Hidden layer terdapat 16 neuron
- Output layer terdapat 1 neuron.
- Fungsi aktivasi relu digunakan pada input dan hidden layer. Sedangkan sigmoid digunakan pada output layer.
- Mengkompilasi model dengan optimizer Adam dengan learning rate 0.001
- Metrik yang digunakan adalah accuracy dan loss function.

## Menerapkan Callbacks

Tujuannya yaitu untuk melakukan penghentian awal otomatis dan menyimpan model yang dianggap terbaik selama iterasi.
"""

# Menerapkan callbacks untuk penghentian awal otomatis
EarlyStopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True
)

# Callbacks untuk menyimpan model yang dianggap terbaik
checkpoint = ModelCheckpoint(
    'best_model_diabetes.h5',
    monitor='val_loss',
    save_best_only=True,
    verbose=1
)

"""Melakukan iterasi sebanyak 20 kali"""

# Melakukan iterasi pada model
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=20,
    batch_size=5,
    callbacks=[EarlyStopping, checkpoint],
    verbose=1
)

"""Menguji hasil model dengan data test"""

loss, accuracy = model.evaluate(X_test, y_test)
print(f'\nAkurasi pada data uji: {accuracy:.2f}')

"""**Insight:**
- Setelah selesai melakukan iterasi, dilakukan evaluasi dengan data test yang menghasilkan akurasi sebesar 0.71 dan loss 0.52

## Evaluasi Model

Mengukur seberapa baik model dengan mengevaluasi hasil akurasi dan loss
"""

# Visualisasi Accuracy pada data training dan data validation
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Akurasi Selama Pelatihan')
plt.xlabel('Epoch')
plt.ylabel('Akurasi')
plt.legend()

# Visualisasi Loss pada data training dan data validation
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Loss Selama Pelatihan')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.tight_layout()
plt.show()

"""**Insight:**
- Grafik Kiri: Akurasi Selama Pelatihan
  - Training Accuracy meningkat secara bertahap dari ~0.60 ke ~0.77.
  - Validation Accuracy juga meningkat, bahkan mencapai ~0.80 di epoch terakhir.
  - Model belajar dengan baik, tidak mengalami overfitting karena akurasi validasi tidak menurun meskipun akurasi training naik.
- Grafik Kanan: Loss Selama Pelatihan
  - Training Loss dan Validation Loss turun signifikan dan cukup sejajar.
  - Validation loss terus menurun hingga akhir epoch, pertanda model terus membaik.
  - Model berhasil mengurangi error baik di data pelatihan maupun validasi
  - Tidak terjadi overfitting maupun underfitting.

Melakukan prediksi dengan data test
"""

# Melakukan prediksi dengan data test
y_pred_prob = model.predict(X_test)
y_pred = (y_pred_prob > 0.5).astype(int)

"""Menggunakan confusion matrix untuk evaluasi model"""

# Melihat nilai akurasi dengan Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

print("\nClassification Report:")
print(classification_report(y_test, y_pred))

"""**Insight:**
- Kelas 0 (Negatif / Tidak Diabetes):
    - Precision (0.82): Dari semua prediksi "tidak diabetes", 82% benar.
    - Recall (0.72): Dari semua kasus nyata "tidak diabetes", 72% berhasil dikenali.
    - F1-score (0.77): Gabungan keseimbangan precision & recall yang cukup tinggi.
- Kelas 1 (Positif / Diabetes):
  - Precision (0.57): Dari semua prediksi "diabetes", hanya 57% yang benar.
  - Recall: (0.71): Dari semua kasus nyata "diabetes", 71% berhasil terdeteksi.
  - F1-score (0.63): Performanya lebih rendah dibanding kelas 0, namun recall masih cukup baik.

**KESIMPULAN:**
- Model memiliki akurasi yang cukup baik (71%), tapi masih bisa ditingkatkan.
- Model lebih bagus dalam mengenali kelas 0 (tidak diabetes) daripada kelas 1 (diabetes).
- Recall untuk kelas 1 cukup tinggi (0.71), cukup bagus untuk deteksi penyakit, karena model berhasil menangkap sebagian besar penderita diabetes.
- Precision untuk kelas 1 rendah (0.57), artinya banyak false positive: orang yang diprediksi menderita diabetes, tapi sebenarnya tidak.
- F1-score kelas 1 (0.63), performa model dalam mendeteksi diabetes masih cukup, tapi perlu ditingkatkan agar lebih andal.

## Inference Model

Melakukan percobaan memasukkan data baru ke model untuk melakukan prediksi
"""

from tensorflow.keras.models import load_model
best_model = load_model('best_model_diabetes.h5')

# Prepare new data for inference (replace with your actual new data)
# Assuming new_data is a pandas DataFrame with the same columns as the training data, excluding 'Outcome'
new_data = pd.DataFrame({
    'Pregnancies': [0, 3, 5, 2, 10],
    'Glucose': [85, 140, 180, 130, 190],
    'BloodPressure': [66, 80, 74, 72, 130],
    'SkinThickness': [29, 35, 0, 25, 15],
    'Insulin': [0, 130, 200, 90, 100],
    'BMI': [26.6, 35.0, 45.3, 30.1, 20.1],
    'DiabetesPedigreeFunction': [0.351, 0.672, 1.201, 0.134, 0.841],
    'Age': [25, 40, 50, 33, 39]
})

# Scale the new data using the same scaler fitted on the training data
new_data_scaled = scaler.transform(new_data)

# Make predictions
predictions = best_model.predict(new_data_scaled)

# Convert probabilities to binary predictions (0 or 1)
predicted_classes = (predictions > 0.5).astype(int)

print("\nInference Results:")
for i in range(len(new_data)):
  print(f"Data Point {i+1}:")
  print(f"  Original Data: {new_data.iloc[i].to_dict()}")
  print(f"  Predicted Probability of Diabetes: {predictions[i][0]:.4f}")
  print(f"  Predicted Class (0: No Diabetes, 1: Diabetes): {predicted_classes[i][0]}")

"""**Insight:**
- Model mampu melakukan prediksi pada data baru meskipun probabilitynya tergolong tidak stabil
"""